{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1a1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54f7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.random.random((256,)) \n",
    "sources = [np.random.random((256,)) for _ in range(10)] \n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    if isinstance(x, list):\n",
    "        x = np.array(x)\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "def score(target, source):\n",
    "    return np.dot(target, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9842105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (256,)\n"
     ]
    }
   ],
   "source": [
    "scores = [score(target, source) for source in sources]\n",
    "scores = softmax(scores)\n",
    "\n",
    "sources_array = np.array(sources) \n",
    "scores = scores[:, np.newaxis]  \n",
    "combined = np.sum(scores * sources_array, axis=0)\n",
    "print(\"Combined shape:\", combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4631756",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.random.random((2, 10, 256)) \n",
    "source = np.random.random((2, 15, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678a2f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25031252, 0.18927063, 0.64347902, ..., 0.54960735,\n",
       "         0.76482802, 0.72117876],\n",
       "        [0.76833941, 0.68287171, 0.90521719, ..., 0.229577  ,\n",
       "         0.77702188, 0.39594471],\n",
       "        [0.32866232, 0.29630267, 0.69959404, ..., 0.48533089,\n",
       "         0.68348005, 0.6437031 ],\n",
       "        ...,\n",
       "        [0.4636575 , 0.47372767, 0.68088346, ..., 0.45750899,\n",
       "         0.63562687, 0.52901039],\n",
       "        [0.26871919, 0.21942518, 0.59846786, ..., 0.52675242,\n",
       "         0.69429453, 0.57669274],\n",
       "        [0.52717543, 0.48146495, 0.73810563, ..., 0.42526169,\n",
       "         0.64766292, 0.56734962]],\n",
       "\n",
       "       [[0.74999776, 0.72400696, 0.48949992, ..., 0.31074765,\n",
       "         0.72149453, 0.87038652],\n",
       "        [0.64736422, 0.61682424, 0.68182485, ..., 0.29378775,\n",
       "         0.7740831 , 0.8775753 ],\n",
       "        [0.64398858, 0.6523471 , 0.6637557 , ..., 0.34248846,\n",
       "         0.73355969, 0.8428566 ],\n",
       "        ...,\n",
       "        [0.7742948 , 0.70673866, 0.54593247, ..., 0.26383247,\n",
       "         0.74783071, 0.88416031],\n",
       "        [0.77945743, 0.71626343, 0.51777474, ..., 0.28410485,\n",
       "         0.73515779, 0.87738463],\n",
       "        [0.40734824, 0.63537259, 0.62316681, ..., 0.48177618,\n",
       "         0.55273197, 0.53782661]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dot_product_attention(target, source):\n",
    "    # Takes the dot-product between all target and source vectors,\n",
    "    # where b = batch size, t = target length, s = source length, and d\n",
    "    # = vector size\n",
    "    scores = np.einsum(\"btd,bsd->bts\", target, source)\n",
    "    scores = softmax(scores, axis=-1)\n",
    "    # Computes a weighted sum of all source vectors for each target\n",
    "    # vector\n",
    "    return np.einsum(\"bts,bsd->btd\", scores, source)\n",
    "\n",
    "dot_product_attention(target, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343db1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10, 256), dtype=float32, numpy=\n",
       "array([[[-0.45054394,  0.9943538 ,  0.5627296 , ...,  1.6444948 ,\n",
       "         -1.4899708 ,  0.1546945 ],\n",
       "        [-0.46762288,  0.82964355,  0.35091782, ...,  1.6376554 ,\n",
       "         -1.3809798 ,  0.06882407],\n",
       "        [-0.44683272,  0.9992876 ,  0.4425981 , ...,  1.7814057 ,\n",
       "         -1.5250347 ,  0.03174876],\n",
       "        ...,\n",
       "        [-0.298494  ,  1.1188456 ,  0.4243595 , ...,  1.7610108 ,\n",
       "         -1.7229068 , -0.09009187],\n",
       "        [-0.42716572,  0.9536388 ,  0.45932785, ...,  1.7388272 ,\n",
       "         -1.472808  ,  0.04370444],\n",
       "        [-0.40345672,  1.0062622 ,  0.41577157, ...,  1.7403771 ,\n",
       "         -1.4994948 ,  0.01196873]],\n",
       "\n",
       "       [[-0.2851899 ,  0.8744449 , -0.0992508 , ...,  1.6036093 ,\n",
       "         -0.98204273,  0.01995445],\n",
       "        [-0.18265052,  0.86011195, -0.01766041, ...,  1.3403437 ,\n",
       "         -0.9777156 , -0.04703699],\n",
       "        [-0.33688113,  0.9273277 , -0.08073823, ...,  1.6231174 ,\n",
       "         -1.0379088 , -0.04480076],\n",
       "        ...,\n",
       "        [ 0.01527208,  0.90698326,  0.10127672, ...,  1.1388026 ,\n",
       "         -0.8874078 , -0.31713787],\n",
       "        [-0.17531861,  0.87469804, -0.02105612, ...,  1.4952921 ,\n",
       "         -0.9393773 , -0.0371419 ],\n",
       "        [-0.10535301,  0.8126714 ,  0.03242712, ...,  1.2740836 ,\n",
       "         -0.94423634, -0.05783856]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 256\n",
    "query_dense = layers.Dense(dim)\n",
    "key_dense = layers.Dense(dim)\n",
    "value_dense = layers.Dense(dim)\n",
    "output_dense = layers.Dense(dim)\n",
    "\n",
    "def parameterized_attention(query, key, value):\n",
    "    query = query_dense(query)\n",
    "    key = key_dense(key)\n",
    "    value = value_dense(value)\n",
    "    scores = np.einsum(\"btd,bsd->bts\", query, key)\n",
    "    scores = softmax(scores, axis=-1)\n",
    "    outputs = np.einsum(\"bts,bsd->btd\", scores, value)\n",
    "    return output_dense(outputs)\n",
    "\n",
    "parameterized_attention(query=target, key=source, value=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1c8519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10, 256), dtype=float32, numpy=\n",
       "array([[[-0.18592608,  0.26163408,  0.4710325 , ..., -0.39132458,\n",
       "          0.5226468 , -0.80184114],\n",
       "        [-0.12332103,  0.27099016,  0.46379867, ..., -0.3735121 ,\n",
       "          0.5170238 , -0.85234153],\n",
       "        [-0.14606842,  0.26755506,  0.47601634, ..., -0.38170898,\n",
       "          0.51592964, -0.8209633 ],\n",
       "        ...,\n",
       "        [-0.18730547,  0.21488252,  0.4682066 , ..., -0.34559852,\n",
       "          0.54162973, -0.8756696 ],\n",
       "        [-0.15994196,  0.23009714,  0.50274456, ..., -0.3487205 ,\n",
       "          0.5180153 , -0.8553152 ],\n",
       "        [-0.15560871,  0.2849512 ,  0.45941752, ..., -0.3650747 ,\n",
       "          0.49716014, -0.81371766]],\n",
       "\n",
       "       [[-0.05722441,  0.2031178 ,  0.7895407 , ..., -0.15143518,\n",
       "          0.5269933 , -0.8113352 ],\n",
       "        [-0.11641002,  0.1742965 ,  0.8289877 , ..., -0.16162756,\n",
       "          0.5644667 , -0.83451295],\n",
       "        [-0.12021776,  0.18370959,  0.8322437 , ..., -0.14184934,\n",
       "          0.5456646 , -0.8362459 ],\n",
       "        ...,\n",
       "        [-0.12181997,  0.18432185,  0.838318  , ..., -0.13716263,\n",
       "          0.52791226, -0.807212  ],\n",
       "        [-0.10273084,  0.20571308,  0.8241695 , ..., -0.1022989 ,\n",
       "          0.55443573, -0.83202916],\n",
       "        [-0.1158931 ,  0.18893135,  0.78631514, ..., -0.18790568,\n",
       "          0.51149225, -0.8451574 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = 32\n",
    "\n",
    "query_dense = [layers.Dense(head_dim) for i in range(num_heads)]\n",
    "key_dense = [layers.Dense(head_dim) for i in range(num_heads)]\n",
    "value_dense = [layers.Dense(head_dim) for i in range(num_heads)]\n",
    "output_dense = layers.Dense(head_dim * num_heads)\n",
    "\n",
    "def multi_head_attention(query, key, value):\n",
    "    head_outputs = []\n",
    "    for i in range(num_heads):\n",
    "        query = query_dense[i](query)\n",
    "        key = key_dense[i](key)\n",
    "        value = value_dense[i](value)\n",
    "        scores = np.einsum(\"btd,bsd->bts\", target, source)\n",
    "        scores = softmax(scores / math.sqrt(head_dim), axis=-1)\n",
    "        head_output = np.einsum(\"bts,bsd->btd\", scores, source)\n",
    "        head_outputs.append(head_output)\n",
    "    outputs = tf.concat(head_outputs, axis=-1)\n",
    "    return output_dense(outputs)\n",
    "\n",
    "multi_head_attention(query=target, key=source, value=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be02f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10, 256), dtype=float32, numpy=\n",
       "array([[[-0.01955285, -0.06889678, -0.09262316, ...,  0.01603702,\n",
       "          0.02627093,  0.10837913],\n",
       "        [-0.01955827, -0.06883085, -0.09258158, ...,  0.01605407,\n",
       "          0.0262757 ,  0.10841117],\n",
       "        [-0.0195565 , -0.06890609, -0.09252397, ...,  0.01604028,\n",
       "          0.02618441,  0.10839273],\n",
       "        ...,\n",
       "        [-0.01962097, -0.06879208, -0.0925836 , ...,  0.01603478,\n",
       "          0.02625707,  0.10837299],\n",
       "        [-0.01960058, -0.06887408, -0.09259455, ...,  0.01609693,\n",
       "          0.0262844 ,  0.10842787],\n",
       "        [-0.01957582, -0.06884725, -0.09255467, ...,  0.01600979,\n",
       "          0.02627961,  0.10836946]],\n",
       "\n",
       "       [[ 0.00014283, -0.07145255, -0.06483021, ...,  0.00980183,\n",
       "          0.02426516,  0.09464476],\n",
       "        [ 0.00023542, -0.07143644, -0.06478545, ...,  0.00982607,\n",
       "          0.02421108,  0.09458698],\n",
       "        [ 0.00013129, -0.07145785, -0.06478333, ...,  0.00984884,\n",
       "          0.02421728,  0.09456387],\n",
       "        ...,\n",
       "        [ 0.00011851, -0.07144654, -0.06480577, ...,  0.00980075,\n",
       "          0.02424663,  0.09465457],\n",
       "        [ 0.00021703, -0.0714734 , -0.06476668, ...,  0.00984609,\n",
       "          0.02430406,  0.09462558],\n",
       "        [ 0.00020747, -0.07146679, -0.06483467, ...,  0.00981777,\n",
       "          0.02424916,  0.09461784]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_attention = keras.layers.MultiHeadAttention(\n",
    "    num_heads=num_heads,\n",
    "    key_dim=head_dim,\n",
    ")\n",
    "multi_head_attention(query=target, key=source, value=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69a171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 15, 256), dtype=float32, numpy=\n",
       "array([[[-0.0194429 , -0.06883302, -0.09258254, ...,  0.01603119,\n",
       "          0.0262194 ,  0.10839305],\n",
       "        [-0.01968635, -0.06889655, -0.09256397, ...,  0.01600354,\n",
       "          0.02627062,  0.10844125],\n",
       "        [-0.01961418, -0.06888583, -0.09260273, ...,  0.01605913,\n",
       "          0.02629185,  0.10839355],\n",
       "        ...,\n",
       "        [-0.0196203 , -0.06884837, -0.0925591 , ...,  0.01605909,\n",
       "          0.02624412,  0.10839172],\n",
       "        [-0.01963696, -0.06886108, -0.09254189, ...,  0.01605135,\n",
       "          0.02622814,  0.10843844],\n",
       "        [-0.01958858, -0.06890504, -0.09257051, ...,  0.01601265,\n",
       "          0.02619541,  0.10845219]],\n",
       "\n",
       "       [[ 0.00018485, -0.07141755, -0.06482642, ...,  0.00985956,\n",
       "          0.02425843,  0.09466682],\n",
       "        [ 0.00017474, -0.07142326, -0.06480012, ...,  0.00971453,\n",
       "          0.02423343,  0.09466703],\n",
       "        [ 0.00026685, -0.07145889, -0.06487991, ...,  0.00986562,\n",
       "          0.02421542,  0.09463257],\n",
       "        ...,\n",
       "        [ 0.0002254 , -0.0714017 , -0.06480252, ...,  0.00980417,\n",
       "          0.02426727,  0.09463114],\n",
       "        [ 0.00019236, -0.07140099, -0.06480351, ...,  0.00984652,\n",
       "          0.02424335,  0.09464153],\n",
       "        [ 0.00019481, -0.07143639, -0.06482216, ...,  0.00987821,\n",
       "          0.02426574,  0.09463575]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_attention(key=source, value=source, query=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0407e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, hidden_dim, intermediate_dim, num_heads):\n",
    "        super().__init__()\n",
    "        key_dim = hidden_dim // num_heads\n",
    "        # Self-attention layers\n",
    "        self.self_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
    "        self.self_attention_layernorm = layers.LayerNormalization()\n",
    "        # Feedforward layers\n",
    "        self.feed_forward_1 = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.feed_forward_2 = layers.Dense(hidden_dim)\n",
    "        self.feed_forward_layernorm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, source, source_mask):\n",
    "        # Self-attention computation\n",
    "        residual = x = source\n",
    "        mask = source_mask[:, None, :]\n",
    "        x = self.self_attention(query=x, key=x, value=x, attention_mask=mask)\n",
    "        x = x + residual\n",
    "        x = self.self_attention_layernorm(x)\n",
    "        # Feedforward computation\n",
    "        residual = x\n",
    "        x = self.feed_forward_1(x)\n",
    "        x = self.feed_forward_2(x)\n",
    "        x = x + residual\n",
    "        x = self.feed_forward_layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1979b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_normalization(batch_of_sequences):\n",
    "    # To compute mean and variance, we only pool data over the last\n",
    "    # axis.\n",
    "    mean = np.mean(batch_of_sequences, keepdims=True, axis=-1)\n",
    "    variance = np.var(batch_of_sequences, keepdims=True, axis=-1)\n",
    "    return (batch_of_sequences - mean) / variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9c23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization(batch_of_images):\n",
    "    # Pools data over the batch axis (axis 0), which creates\n",
    "    # interactions between samples in a batch\n",
    "    mean = np.mean(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
    "    variance = np.var(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
    "    return (batch_of_images - mean) / variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7adca74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer decoder\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, hidden_dim, intermediate_dim, num_heads):\n",
    "        super().__init__()\n",
    "        key_dim = hidden_dim // num_heads\n",
    "        # Self-attention layers\n",
    "        self.self_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
    "        self.self_attention_layernorm = layers.LayerNormalization()\n",
    "        # Cross-attention layers\n",
    "        self.cross_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
    "        self.cross_attention_layernorm = layers.LayerNormalization()\n",
    "        # Feedforward layers\n",
    "        self.feed_forward_1 = layers.Dense(intermediate_dim, activation=\"relu\")\n",
    "        self.feed_forward_2 = layers.Dense(hidden_dim)\n",
    "        self.feed_forward_layernorm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, target, source, source_mask):\n",
    "        # Self-attention computation\n",
    "        residual = x = target\n",
    "        x = self.self_attention(query=x, key=x, value=x, use_causal_mask=True)\n",
    "        x = x + residual\n",
    "        x = self.self_attention_layernorm(x)\n",
    "        # Cross-attention computation\n",
    "        residual = x\n",
    "        mask = source_mask[:, None, :]\n",
    "        x = self.cross_attention(\n",
    "            query=x, key=source, value=source, attention_mask=mask\n",
    "        )\n",
    "        x = x + residual\n",
    "        x = self.cross_attention_layernorm(x)\n",
    "        # Feedforward computation\n",
    "        residual = x\n",
    "        x = self.feed_forward_1(x)\n",
    "        x = self.feed_forward_2(x)\n",
    "        x = x + residual\n",
    "        x = self.feed_forward_layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b9621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = layers.Embedding(input_dim, output_dim)\n",
    "        self.position_embeddings = layers.Embedding(sequence_length, output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Computes incrementing positions [0, 1, 2...] for each\n",
    "        # sequence in the batch\n",
    "        positions = tf.cumsum(tf.ones_like(inputs), axis=-1) - 1\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e7d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anhng\\Desktop\\CECS 451\\Assignment_6\\myenv_tf\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "intermediate_dim = 2048\n",
    "num_heads = 8\n",
    "vocab_size = 15000\n",
    " \n",
    "source = keras.Input(shape=(None,), dtype=\"int32\", name=\"english\")\n",
    "x = layers.Embedding(vocab_size, hidden_dim)(source)\n",
    "encoder_output = TransformerEncoder(hidden_dim, intermediate_dim, num_heads)(\n",
    "    source=x,\n",
    "    source_mask=source != 0,\n",
    ")\n",
    " \n",
    "target = keras.Input(shape=(None,), dtype=\"int32\", name=\"spanish\")\n",
    "x = layers.Embedding(vocab_size, hidden_dim)(target)\n",
    "x = TransformerDecoder(hidden_dim, intermediate_dim, num_heads)(\n",
    "    target=x,\n",
    "    source=encoder_output,\n",
    "    source_mask=source != 0,\n",
    ")\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_predictions = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([source, target], target_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe135fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,578,752</span> │ transformer_enco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,840,000\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,072\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,840,000\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,578,752\u001b[0m │ transformer_enco… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,428,824</span> (55.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,428,824\u001b[0m (55.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,428,824</span> (55.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,428,824\u001b[0m (55.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42bec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "sequence_length = 20\n",
    "train_pairs = [\n",
    "    (\"Who is in this room?\", \"[start] ¿Quién está en esta habitación? [end]\"),\n",
    "    (\"Hello, how are you?\", \"[start] Hola, ¿cómo estás? [end]\"),\n",
    "    (\"What is your name?\", \"[start] ¿Cuál es tu nombre? [end]\"),\n",
    "    (\"Nice to meet you.\", \"[start] Mucho gusto. [end]\"),\n",
    "    (\"Where is the bathroom?\", \"[start] ¿Dónde está el baño? [end]\"),\n",
    "    (\"I am hungry.\", \"[start] Tengo hambre. [end]\"),\n",
    "    (\"How much does it cost?\", \"[start] ¿Cuánto cuesta? [end]\"),\n",
    "    (\"I don't understand.\", \"[start] No entiendo. [end]\"),\n",
    "    (\"Can you help me?\", \"[start] ¿Puedes ayudarme? [end]\"),\n",
    "    (\"Thank you very much.\", \"[start] Muchas gracias. [end]\"),\n",
    "    (\"You're welcome.\", \"[start] De nada. [end]\"),\n",
    "    (\"I love this place.\", \"[start] Me encanta este lugar. [end]\"),\n",
    "    (\"What time is it?\", \"[start] ¿Qué hora es? [end]\"),\n",
    "    (\"Where do you live?\", \"[start] ¿Dónde vives? [end]\"),\n",
    "    (\"I am from the United States.\", \"[start] Soy de Estados Unidos. [end]\"),\n",
    "    (\"Do you speak English?\", \"[start] ¿Hablas inglés? [end]\"),\n",
    "    (\"I need a doctor.\", \"[start] Necesito un médico. [end]\"),\n",
    "    (\"How old are you?\", \"[start] ¿Cuántos años tienes? [end]\"),\n",
    "    (\"This is delicious.\", \"[start] Esto está delicioso. [end]\"),\n",
    "    (\"See you tomorrow.\", \"[start] Hasta mañana. [end]\"),\n",
    "]\n",
    "val_pairs = [\n",
    "    (\"Goodbye.\", \"[start] Adiós. [end]\"),\n",
    "    (\"Good morning.\", \"[start] Buenos días. [end]\"),\n",
    "    (\"Have a nice day.\", \"[start] Que tengas un buen día. [end]\"),\n",
    "    (\"I am learning Spanish.\", \"[start] Estoy aprendiendo español. [end]\"),\n",
    "]\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\"\n",
    "    )\n",
    "\n",
    "english_tokenizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "spanish_tokenizer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# Adapt tokenizers to the training data\n",
    "eng_texts, spa_texts = zip(*train_pairs)\n",
    "english_tokenizer.adapt(eng_texts)\n",
    "spanish_tokenizer.adapt(spa_texts)\n",
    "def format_dataset(eng, spa):\n",
    "    eng = english_tokenizer(eng)\n",
    "    spa = spanish_tokenizer(spa)\n",
    "    features = {\"english\": eng, \"spanish\": spa[:, :-1]}\n",
    "    labels = spa[:, 1:]\n",
    "    sample_weights = labels != 0\n",
    "    return features, labels, sample_weights\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).cache()\n",
    "\n",
    "batch_size = 64\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
