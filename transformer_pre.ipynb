{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-hub tensorflow-text -q"
      ],
      "metadata": {
        "id": "OGSWpLphzz9K"
      },
      "id": "OGSWpLphzz9K",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d13952d0",
      "metadata": {
        "id": "d13952d0"
      },
      "outputs": [],
      "source": [
        "import keras_hub\n",
        "\n",
        "tokenizer = keras_hub.models.Tokenizer.from_preset(\"roberta_base_en\")\n",
        "backbone = keras_hub.models.Backbone.from_preset(\"roberta_base_en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d104c18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d104c18",
        "outputId": "a3587108-209e-4fef-e37c-2a62168f08c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([  133,  2119,  6219, 23602], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tokenizer(\"The quick brown fox\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up and start fresh\n",
        "!rm -rf aclImdb aclImdb_v1.tar.gz aclImdb_v1.tar.gz_archive\n",
        "\n",
        "# Download the dataset\n",
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "\n",
        "# Extract it\n",
        "!tar -xzf aclImdb_v1.tar.gz\n",
        "\n",
        "# Remove unsupervised folder\n",
        "!rm -rf aclImdb/train/unsup\n",
        "\n",
        "# Verify extraction worked\n",
        "!ls -la aclImdb/\n",
        "!ls -la aclImdb/train/\n",
        "\n",
        "# Define paths\n",
        "train_dir = \"aclImdb/train\"\n",
        "test_dir = \"aclImdb/test\"\n",
        "val_dir = \"aclImdb/test\"\n",
        "\n",
        "print(\"\\nDirectories defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VBlRy4-2LUT",
        "outputId": "5152585a-6ef5-4f67-cf5d-6307869848f1"
      },
      "id": "-VBlRy4-2LUT",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 04:34:24--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  27.5MB/s    in 2.9s    \n",
            "\n",
            "2025-11-29 04:34:27 (27.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "total 1732\n",
            "drwxr-xr-x 4 7297 1000   4096 Jun 26  2011 .\n",
            "drwxr-xr-x 1 root root   4096 Nov 29 04:34 ..\n",
            "-rw-r--r-- 1 7297 1000 903029 Jun 11  2011 imdbEr.txt\n",
            "-rw-r--r-- 1 7297 1000 845980 Apr 12  2011 imdb.vocab\n",
            "-rw-r--r-- 1 7297 1000   4037 Jun 26  2011 README\n",
            "drwxr-xr-x 4 7297 1000   4096 Nov 29 04:34 test\n",
            "drwxr-xr-x 4 7297 1000   4096 Nov 29 04:34 train\n",
            "total 65200\n",
            "drwxr-xr-x 4 7297 1000     4096 Nov 29 04:34 .\n",
            "drwxr-xr-x 4 7297 1000     4096 Jun 26  2011 ..\n",
            "-rw-r--r-- 1 7297 1000 21021197 Apr 12  2011 labeledBow.feat\n",
            "drwxr-xr-x 2 7297 1000   356352 Nov 29 04:34 neg\n",
            "drwxr-xr-x 2 7297 1000   335872 Nov 29 04:34 pos\n",
            "-rw-r--r-- 1 7297 1000 41348699 Apr 12  2011 unsupBow.feat\n",
            "-rw-r--r-- 1 7297 1000   612500 Apr 12  2011 urls_neg.txt\n",
            "-rw-r--r-- 1 7297 1000   612500 Apr 12  2011 urls_pos.txt\n",
            "-rw-r--r-- 1 7297 1000  2450000 Apr 12  2011 urls_unsup.txt\n",
            "\n",
            "Directories defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import text_dataset_from_directory\n",
        "\n",
        "batch_size = 16\n",
        "train_ds = text_dataset_from_directory(train_dir, batch_size=batch_size)\n",
        "val_ds = text_dataset_from_directory(val_dir, batch_size=batch_size)\n",
        "test_ds = text_dataset_from_directory(test_dir, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVgCINJx1YBL",
        "outputId": "750d2bc2-25de-4662-e4ff-2cfefb894952"
      },
      "id": "LVgCINJx1YBL",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, label):\n",
        "    packer = keras_hub.layers.StartEndPacker(\n",
        "        sequence_length=512,\n",
        "        start_value=tokenizer.start_token_id,\n",
        "        end_value=tokenizer.end_token_id,\n",
        "        pad_value=tokenizer.pad_token_id,\n",
        "        return_padding_mask=True,\n",
        "    )\n",
        "    token_ids, padding_mask = packer(tokenizer(text))\n",
        "    return {\"token_ids\": token_ids, \"padding_mask\": padding_mask}, label\n",
        "\n",
        "preprocessed_train_ds = train_ds.map(preprocess)\n",
        "preprocessed_val_ds = val_ds.map(preprocess)\n",
        "preprocessed_test_ds = test_ds.map(preprocess)"
      ],
      "metadata": {
        "id": "Xy2M8PZW3UDe"
      },
      "id": "Xy2M8PZW3UDe",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(preprocessed_train_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KggV4q4I3VIA",
        "outputId": "55e71513-b65a-48d3-c0a7-5860e97bbfd8"
      },
      "id": "KggV4q4I3VIA",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'token_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
              "  array([[    0,   713,    16, ...,     1,     1,     1],\n",
              "         [    0,  7516,     6, ...,     1,     1,     1],\n",
              "         [    0,   713,  1569, ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,  9335,    98, ...,     1,     1,     1],\n",
              "         [    0,   565,  5593, ...,     1,     1,     1],\n",
              "         [    0, 30115,  4186, ...,   160,    41,     2]], dtype=int32)>,\n",
              "  'padding_mask': <tf.Tensor: shape=(16, 512), dtype=bool, numpy=\n",
              "  array([[ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         ...,\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ...,  True,  True,  True]])>},\n",
              " <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = backbone.input\n",
        "x = backbone(inputs)\n",
        "# Uses the hidden representation of the first token\n",
        "x = x[:, 0, :]\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(768, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "classifier = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "3omMKMVl3pfD"
      },
      "id": "3omMKMVl3pfD",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(5e-5),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "classifier.fit(\n",
        "    preprocessed_train_ds,\n",
        "    validation_data=preprocessed_val_ds,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUxSa4wS3sMX",
        "outputId": "44f866f6-5e10-45a6-a055-34985e69513b"
      },
      "id": "hUxSa4wS3sMX",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3311s\u001b[0m 2s/step - accuracy: 0.8600 - loss: 0.3268 - val_accuracy: 0.9358 - val_loss: 0.1692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ace0026e5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(preprocessed_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLAFYFyE3tn8",
        "outputId": "bffa8e7c-bfac-470e-8a13-7d0545c51ac6"
      },
      "id": "WLAFYFyE3tn8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 537ms/step - accuracy: 0.9369 - loss: 0.1644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1691877543926239, 0.9358400106430054]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}